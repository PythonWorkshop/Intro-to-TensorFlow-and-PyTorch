{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality -TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Load the data\n",
    "Read the cleanded data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-red-cleaned.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of the following columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol' 'quality' 'category']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features are: ['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol']\n",
      "The label column is: category\n"
     ]
    }
   ],
   "source": [
    "features_list = df.columns.values[:-2]\n",
    "labels_column = df.columns.values[-1]\n",
    "print('The features are: {}'.format(features_list))\n",
    "print('The label column is: {}'.format(labels_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into features and labels. Labels will be convert from string values to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y = [0 if item == 'Good' else 1 for item in df['category']]\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['quality', 'category'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Vectors\n",
    "In this implementation of TensorFlow the labels need to be expressed as one-hot vectors. A one-hot vector has length equal to the number of catetories and values of 0 and 1. For examples, category value **Good** == 0 => **`[0, 1]`**, while **Bad** == 1 => **`[1, 0]`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define a function to convert the numeric labels into one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=2):\n",
    "    labels_one_hot = []\n",
    "    for label in labels_dense:\n",
    "        indices = [1]*num_classes\n",
    "        indices[label] = 0\n",
    "        labels_one_hot.append(indices)\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [1, 0], [1, 0], [0, 1], [1, 0]]\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = dense_to_one_hot(y, num_classes=2)\n",
    "print(y_one_hot[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "These are parameters that can be changed to modify how the model is fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = X_train.shape[0] // 10\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "epochs_to_print = epochs // 10\n",
    "hidden_layer_units = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "TensorFlow stores fixed quantities, like the features and labels, in a **`placeholder()`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_placeholder = tf.placeholder(tf.float32, [None, num_features], name='X')\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, num_classes], name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches\n",
    "The model is trained by taking random sambles from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(X, y, batch_size):\n",
    "    \n",
    "    y_size = len(y)\n",
    "    index_sample = np.random.choice(y_size, batch_size, replace=False)\n",
    "    y_array = np.array(y)\n",
    "    \n",
    "    X_batch = X[index_sample]\n",
    "    y_batch = y_array[index_sample]\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Layer\n",
    "Use softmax regression to model the data. Set up the model weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_layer(X_tensor, num_units):\n",
    "    num_inputs = X_tensor.get_shape()[1].value\n",
    "    W = tf.Variable(tf.zeros([num_inputs, num_units]), name='W')\n",
    "    b = tf.Variable(tf.zeros([num_units]), name='b')\n",
    "    y = tf.nn.softmax(tf.matmul(X_tensor, W) + b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu Layer\n",
    "Model complexity can be increased by adding additional layers. Here I define a function to create a ReLu layer, which can be added to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_layer(X_tensor, num_units):\n",
    "    num_inputs = X_tensor.get_shape()[1].value\n",
    "    # W = tf.Variable(tf.zeros([num_features, num_units]), name='W')\n",
    "    W = tf.Variable(tf.random.uniform([num_features, num_units]), name='W')\n",
    "    b = tf.Variable(tf.zeros([num_units]), name='b')\n",
    "    y = tf.nn.relu(tf.matmul(X_tensor, W) + b, name='relu')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the error using cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_cost_function(y, y_tensor, batch_size):\n",
    "    cost = -tf.reduce_sum(y_tensor * tf.log(y), name='cross_entropy') / batch_size\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step\n",
    "Define the optimizer. I use gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(cost, learning_rate):\n",
    "    training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    return training_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "This function will be used to compute model accuracy during training and at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_tensor):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_tensor, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), name='accuracy')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph\n",
    "Now that we have defined functions to make the TensorFlow graph, here is where we actually create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_layer():\n",
    "    # Create softmax layer\n",
    "    with tf.name_scope(\"softmax\") as scope:\n",
    "        y_softmax = softmax_layer(X_placeholder, num_classes)\n",
    "\n",
    "    # Define cost function\n",
    "    with tf.name_scope(\"cost_function\") as scope:\n",
    "        global cost\n",
    "        cost = define_cost_function(y_softmax, y_placeholder, batch_size)\n",
    "        tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "    # Define training step\n",
    "    with tf.name_scope(\"training\") as scope:\n",
    "        global training_step\n",
    "        training_step = train(cost, learning_rate)\n",
    "\n",
    "    # Calculate model accuracy\n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        global accuracy\n",
    "        accuracy = compute_accuracy(y_softmax, y_placeholder)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_layers():\n",
    "    # Create hidden, relu layer\n",
    "    with tf.name_scope(\"hidden_layer\") as scope:\n",
    "        y_relu = relu_layer(X_placeholder, hidden_layer_units)\n",
    "    \n",
    "    # Create softmax layer\n",
    "    with tf.name_scope(\"softmax\") as scope:\n",
    "        y_softmax = softmax_layer(y_relu, num_classes)\n",
    "\n",
    "    # Define cost function\n",
    "    with tf.name_scope(\"cost_function\") as scope:\n",
    "        global cost\n",
    "        cost = define_cost_function(y_softmax, y_placeholder, batch_size)\n",
    "        tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "    # Define training step\n",
    "    with tf.name_scope(\"training\") as scope:\n",
    "        global training_step\n",
    "        training_step = train(cost, learning_rate)\n",
    "\n",
    "    # Calculate model accuracy\n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        global accuracy\n",
    "        accuracy = compute_accuracy(y_softmax, y_placeholder)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_layer()\n",
    "# two_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "A TensorFlow session is started and the model is trained using the graph that we setup above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  100, average cost = 0.682\n",
      "Epoch:  200, average cost = 0.663\n",
      "Epoch:  300, average cost = 0.646\n",
      "Epoch:  400, average cost = 0.633\n",
      "Epoch:  500, average cost = 0.621\n",
      "Epoch:  600, average cost = 0.612\n",
      "Epoch:  700, average cost = 0.604\n",
      "Epoch:  800, average cost = 0.594\n",
      "Epoch:  900, average cost = 0.586\n",
      "Epoch: 1000, average cost = 0.580\n",
      "Finished model fitting.\n",
      "Final accuracy = 0.731\n"
     ]
    }
   ],
   "source": [
    "# Merge summaries for TensorBoard\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    log_directory = 'tmp/logs'\n",
    "    summary_writer = tf.summary.FileWriter(log_directory, sess.graph)\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # average_cost = 0\n",
    "    cost_sum = 0\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        X_batch, y_batch = make_batch(X_train, y_train, batch_size)\n",
    "        feed_dict = {X_placeholder: X_batch, y_placeholder: y_batch}\n",
    "        _, current_cost = sess.run([training_step, cost], feed_dict)\n",
    "        cost_sum += current_cost\n",
    "        \n",
    "        # Print average cost periodically\n",
    "        if i % epochs_to_print == 99:\n",
    "            average_cost = cost_sum / epochs_to_print\n",
    "            print(\"Epoch: {:4d}, average cost = {:0.3f}\".format(i+1, average_cost))\n",
    "            cost_sum = 0\n",
    "    \n",
    "    print('Finished model fitting.')\n",
    " \n",
    "    # Calculate final accuracy\n",
    "    X_batch, y_batch = make_batch(X_test, y_test, batch_size)\n",
    "    feed_dict = {X_placeholder: X_test, y_placeholder: y_test}\n",
    "    print(\"Final accuracy = {:0.3f}\".format(sess.run(accuracy, feed_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

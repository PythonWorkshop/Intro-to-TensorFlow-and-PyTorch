{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/winequality-red-cleaned.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961877</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.967442</td>\n",
       "      <td>0.043416</td>\n",
       "      <td>0.223875</td>\n",
       "      <td>0.624363</td>\n",
       "      <td>-0.719933</td>\n",
       "      <td>0.128950</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.297065</td>\n",
       "      <td>-0.169427</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.229047</td>\n",
       "      <td>-0.331177</td>\n",
       "      <td>-0.048089</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.384443</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.264960</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>-0.979104</td>\n",
       "      <td>-0.461180</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>6</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.961877</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   volatile acidity  residual sugar  chlorides  total sulfur dioxide  \\\n",
       "0          0.961877       -0.453218  -0.243707             -0.379133   \n",
       "1          1.967442        0.043416   0.223875              0.624363   \n",
       "2          1.297065       -0.169427   0.096353              0.229047   \n",
       "3         -1.384443       -0.453218  -0.264960              0.411500   \n",
       "4          0.961877       -0.453218  -0.243707             -0.379133   \n",
       "\n",
       "         pH  sulphates   alcohol  quality category  \n",
       "0  1.288643  -0.579207 -0.960246        5      Bad  \n",
       "1 -0.719933   0.128950 -0.584777        5      Bad  \n",
       "2 -0.331177  -0.048089 -0.584777        5      Bad  \n",
       "3 -0.979104  -0.461180 -0.584777        6     Good  \n",
       "4  1.288643  -0.579207 -0.960246        5      Bad  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame([0. if item == 'Good' else 1. for item in df['category']])\n",
    "y = [0. if item == 'Good' else 1. for item in df['category']]\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_df = df.drop(['quality', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961877</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.967442</td>\n",
       "      <td>0.043416</td>\n",
       "      <td>0.223875</td>\n",
       "      <td>0.624363</td>\n",
       "      <td>-0.719933</td>\n",
       "      <td>0.128950</td>\n",
       "      <td>-0.584777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.297065</td>\n",
       "      <td>-0.169427</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.229047</td>\n",
       "      <td>-0.331177</td>\n",
       "      <td>-0.048089</td>\n",
       "      <td>-0.584777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.384443</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.264960</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>-0.979104</td>\n",
       "      <td>-0.461180</td>\n",
       "      <td>-0.584777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.961877</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   volatile acidity  residual sugar  chlorides  total sulfur dioxide  \\\n",
       "0          0.961877       -0.453218  -0.243707             -0.379133   \n",
       "1          1.967442        0.043416   0.223875              0.624363   \n",
       "2          1.297065       -0.169427   0.096353              0.229047   \n",
       "3         -1.384443       -0.453218  -0.264960              0.411500   \n",
       "4          0.961877       -0.453218  -0.243707             -0.379133   \n",
       "\n",
       "         pH  sulphates   alcohol  \n",
       "0  1.288643  -0.579207 -0.960246  \n",
       "1 -0.719933   0.128950 -0.584777  \n",
       "2 -0.331177  -0.048089 -0.584777  \n",
       "3 -0.979104  -0.461180 -0.584777  \n",
       "4  1.288643  -0.579207 -0.960246  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = torch.from_numpy(features_df.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = torch.from_numpy(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: pip install sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, y, test_size=0.2, random_state=42)\n",
    "# X_train = features_df\n",
    "# y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "batch_size = 126\n",
    "epochs = 1000\n",
    "epochs_to_print = epochs / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7050687074661255\n",
      "1 loss: 0.007\n",
      "0.8019934296607971\n",
      "1 loss: 0.008\n",
      "0.81717848777771\n",
      "1 loss: 0.008\n",
      "0.80559241771698\n",
      "1 loss: 0.008\n",
      "0.832951009273529\n",
      "1 loss: 0.008\n",
      "0.7637039422988892\n",
      "1 loss: 0.008\n",
      "0.7856991291046143\n",
      "1 loss: 0.008\n",
      "0.8053922653198242\n",
      "1 loss: 0.008\n",
      "0.8317679166793823\n",
      "1 loss: 0.008\n",
      "0.7746209502220154\n",
      "1 loss: 0.008\n",
      "0.7050687074661255\n",
      "101 loss: 0.007\n",
      "0.8019934296607971\n",
      "101 loss: 0.008\n",
      "0.81717848777771\n",
      "101 loss: 0.008\n",
      "0.80559241771698\n",
      "101 loss: 0.008\n",
      "0.832951009273529\n",
      "101 loss: 0.008\n",
      "0.7637039422988892\n",
      "101 loss: 0.008\n",
      "0.7856991291046143\n",
      "101 loss: 0.008\n",
      "0.8053922653198242\n",
      "101 loss: 0.008\n",
      "0.8317679166793823\n",
      "101 loss: 0.008\n",
      "0.7746209502220154\n",
      "101 loss: 0.008\n",
      "0.7050687074661255\n",
      "201 loss: 0.007\n",
      "0.8019934296607971\n",
      "201 loss: 0.008\n",
      "0.81717848777771\n",
      "201 loss: 0.008\n",
      "0.80559241771698\n",
      "201 loss: 0.008\n",
      "0.832951009273529\n",
      "201 loss: 0.008\n",
      "0.7637039422988892\n",
      "201 loss: 0.008\n",
      "0.7856991291046143\n",
      "201 loss: 0.008\n",
      "0.8053922653198242\n",
      "201 loss: 0.008\n",
      "0.8317679166793823\n",
      "201 loss: 0.008\n",
      "0.7746209502220154\n",
      "201 loss: 0.008\n",
      "0.7050687074661255\n",
      "301 loss: 0.007\n",
      "0.8019934296607971\n",
      "301 loss: 0.008\n",
      "0.81717848777771\n",
      "301 loss: 0.008\n",
      "0.80559241771698\n",
      "301 loss: 0.008\n",
      "0.832951009273529\n",
      "301 loss: 0.008\n",
      "0.7637039422988892\n",
      "301 loss: 0.008\n",
      "0.7856991291046143\n",
      "301 loss: 0.008\n",
      "0.8053922653198242\n",
      "301 loss: 0.008\n",
      "0.8317679166793823\n",
      "301 loss: 0.008\n",
      "0.7746209502220154\n",
      "301 loss: 0.008\n",
      "0.7050687074661255\n",
      "401 loss: 0.007\n",
      "0.8019934296607971\n",
      "401 loss: 0.008\n",
      "0.81717848777771\n",
      "401 loss: 0.008\n",
      "0.80559241771698\n",
      "401 loss: 0.008\n",
      "0.832951009273529\n",
      "401 loss: 0.008\n",
      "0.7637039422988892\n",
      "401 loss: 0.008\n",
      "0.7856991291046143\n",
      "401 loss: 0.008\n",
      "0.8053922653198242\n",
      "401 loss: 0.008\n",
      "0.8317679166793823\n",
      "401 loss: 0.008\n",
      "0.7746209502220154\n",
      "401 loss: 0.008\n",
      "0.7050687074661255\n",
      "501 loss: 0.007\n",
      "0.8019934296607971\n",
      "501 loss: 0.008\n",
      "0.81717848777771\n",
      "501 loss: 0.008\n",
      "0.80559241771698\n",
      "501 loss: 0.008\n",
      "0.832951009273529\n",
      "501 loss: 0.008\n",
      "0.7637039422988892\n",
      "501 loss: 0.008\n",
      "0.7856991291046143\n",
      "501 loss: 0.008\n",
      "0.8053922653198242\n",
      "501 loss: 0.008\n",
      "0.8317679166793823\n",
      "501 loss: 0.008\n",
      "0.7746209502220154\n",
      "501 loss: 0.008\n",
      "0.7050687074661255\n",
      "601 loss: 0.007\n",
      "0.8019934296607971\n",
      "601 loss: 0.008\n",
      "0.81717848777771\n",
      "601 loss: 0.008\n",
      "0.80559241771698\n",
      "601 loss: 0.008\n",
      "0.832951009273529\n",
      "601 loss: 0.008\n",
      "0.7637039422988892\n",
      "601 loss: 0.008\n",
      "0.7856991291046143\n",
      "601 loss: 0.008\n",
      "0.8053922653198242\n",
      "601 loss: 0.008\n",
      "0.8317679166793823\n",
      "601 loss: 0.008\n",
      "0.7746209502220154\n",
      "601 loss: 0.008\n",
      "0.7050687074661255\n",
      "701 loss: 0.007\n",
      "0.8019934296607971\n",
      "701 loss: 0.008\n",
      "0.81717848777771\n",
      "701 loss: 0.008\n",
      "0.80559241771698\n",
      "701 loss: 0.008\n",
      "0.832951009273529\n",
      "701 loss: 0.008\n",
      "0.7637039422988892\n",
      "701 loss: 0.008\n",
      "0.7856991291046143\n",
      "701 loss: 0.008\n",
      "0.8053922653198242\n",
      "701 loss: 0.008\n",
      "0.8317679166793823\n",
      "701 loss: 0.008\n",
      "0.7746209502220154\n",
      "701 loss: 0.008\n",
      "0.7050687074661255\n",
      "801 loss: 0.007\n",
      "0.8019934296607971\n",
      "801 loss: 0.008\n",
      "0.81717848777771\n",
      "801 loss: 0.008\n",
      "0.80559241771698\n",
      "801 loss: 0.008\n",
      "0.832951009273529\n",
      "801 loss: 0.008\n",
      "0.7637039422988892\n",
      "801 loss: 0.008\n",
      "0.7856991291046143\n",
      "801 loss: 0.008\n",
      "0.8053922653198242\n",
      "801 loss: 0.008\n",
      "0.8317679166793823\n",
      "801 loss: 0.008\n",
      "0.7746209502220154\n",
      "801 loss: 0.008\n",
      "0.7050687074661255\n",
      "901 loss: 0.007\n",
      "0.8019934296607971\n",
      "901 loss: 0.008\n",
      "0.81717848777771\n",
      "901 loss: 0.008\n",
      "0.80559241771698\n",
      "901 loss: 0.008\n",
      "0.832951009273529\n",
      "901 loss: 0.008\n",
      "0.7637039422988892\n",
      "901 loss: 0.008\n",
      "0.7856991291046143\n",
      "901 loss: 0.008\n",
      "0.8053922653198242\n",
      "901 loss: 0.008\n",
      "0.8317679166793823\n",
      "901 loss: 0.008\n",
      "0.7746209502220154\n",
      "901 loss: 0.008\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(epochs): # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for start, end in zip(range(0, len(X_train), batch_size), \n",
    "                          range(batch_size, len(X_train), batch_size)):\n",
    "        # get the inputs\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[start:end].as_matrix())\n",
    "        inputs = inputs.float()\n",
    "        labels = torch.Tensor(y_train[start:end])\n",
    "        labels = labels.long()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if epoch % epochs_to_print == 0:\n",
    "            print(loss.data[0])\n",
    "            print('%d loss: %.3f' % (epoch+1, running_loss / epochs_to_print))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = net(Variable(torch.from_numpy(X_test.as_matrix()).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2278 -0.2686\n",
       "-0.0934 -0.6461\n",
       " 0.9509  0.2293\n",
       "-0.0093 -0.3103\n",
       " 0.2688  0.3197\n",
       "-0.3921 -0.3179\n",
       " 0.4485 -1.2844\n",
       " 0.0185  0.4320\n",
       " 0.6816  0.0087\n",
       " 0.3159  0.8576\n",
       " 1.0107  0.1433\n",
       " 0.1086  0.9090\n",
       " 0.2555 -0.0023\n",
       " 0.1596 -0.0837\n",
       "-0.1149 -0.3554\n",
       " 0.6805  0.4540\n",
       " 0.1972 -0.3665\n",
       " 0.2784 -0.4089\n",
       " 1.2121  0.2237\n",
       " 1.1209 -0.3195\n",
       "-0.5688  0.3195\n",
       " 0.0874 -0.1692\n",
       " 0.4145  1.0045\n",
       " 0.7105  0.5407\n",
       " 0.1598  0.3867\n",
       "-0.0036  0.4986\n",
       " 0.1450 -0.3110\n",
       " 0.0064  0.3585\n",
       "-0.5806 -0.9479\n",
       " 0.1719 -0.0043\n",
       " 0.1338 -0.3316\n",
       "-0.3272  0.0113\n",
       " 0.3421 -0.0204\n",
       " 0.5787 -0.1128\n",
       " 0.2828  0.4691\n",
       " 0.1444 -0.8405\n",
       " 0.7067  0.7682\n",
       " 0.5418  0.9353\n",
       " 1.1372 -0.1941\n",
       " 0.5233  0.4342\n",
       " 0.8480 -0.5082\n",
       " 0.2070 -0.8048\n",
       " 0.8991 -0.2977\n",
       " 0.8100 -1.0490\n",
       " 1.0235 -0.1778\n",
       " 1.2606  0.6733\n",
       " 1.1835  0.3641\n",
       " 0.6185 -0.6355\n",
       " 0.7252  0.0990\n",
       " 0.4243  0.4551\n",
       " 0.2078 -1.1969\n",
       " 1.7513 -0.6638\n",
       " 0.5134  0.6934\n",
       " 1.5184  0.8100\n",
       "-0.1867  0.0899\n",
       " 0.5852 -0.8730\n",
       " 0.9173  0.7369\n",
       "-0.3425 -0.3347\n",
       " 0.1169  0.2352\n",
       "-0.0619  0.7319\n",
       " 0.1984 -0.4466\n",
       " 0.5054 -0.0387\n",
       "-0.1269 -0.1307\n",
       "-0.3720 -0.1490\n",
       " 0.8597  0.4386\n",
       "-0.5869 -0.4145\n",
       " 0.6102  0.2314\n",
       "-0.1286  0.9353\n",
       " 0.7883  0.7827\n",
       "-0.0450 -0.4396\n",
       " 0.4730  0.5891\n",
       " 0.5462 -0.1198\n",
       " 0.4530 -0.2018\n",
       " 0.1778  0.5717\n",
       " 0.7012  0.5788\n",
       " 0.5613 -0.5429\n",
       " 1.5375  0.7493\n",
       " 0.5624 -0.4242\n",
       " 0.8391  0.4082\n",
       " 0.5276  0.1164\n",
       "-0.6982  0.6957\n",
       " 1.0306  0.3677\n",
       " 0.3898  0.0805\n",
       "-0.0934  0.0959\n",
       " 0.0703 -0.1704\n",
       " 1.4461 -0.0863\n",
       "-0.1050 -0.4834\n",
       " 0.4684  1.0032\n",
       " 1.0437  0.2760\n",
       " 0.0477  0.9337\n",
       " 0.9804  0.0413\n",
       "-0.5061 -2.0554\n",
       "-0.0655  1.3690\n",
       " 0.8012  0.0272\n",
       " 0.0526 -0.7955\n",
       " 0.3079 -0.3018\n",
       " 0.3353 -0.5900\n",
       " 0.7144 -0.0341\n",
       "-0.1673  0.6425\n",
       " 0.2435  0.1169\n",
       " 0.1054  0.7236\n",
       "-0.1860  0.2656\n",
       " 0.5713 -0.2864\n",
       "-0.4929  0.1110\n",
       " 0.8503  0.2385\n",
       " 0.6820  0.3814\n",
       " 0.6725 -0.6397\n",
       " 0.1308 -0.6543\n",
       "-0.8949 -0.7366\n",
       " 1.0695 -0.4014\n",
       " 0.6784  1.5060\n",
       "-0.0273 -1.0738\n",
       " 0.3854  0.0090\n",
       " 0.7439 -1.3183\n",
       " 0.3566  0.0457\n",
       " 0.8212 -0.6012\n",
       " 0.8368  1.1954\n",
       "-0.0517 -0.1032\n",
       "-0.0500 -0.2103\n",
       " 0.5405  0.4910\n",
       " 0.5799 -0.1125\n",
       " 0.5839  0.3206\n",
       " 0.5404  0.0857\n",
       " 0.7452  0.1704\n",
       "-0.0096  0.2921\n",
       " 0.1617  0.0534\n",
       " 1.2197 -0.1943\n",
       " 0.2292 -0.1461\n",
       "-0.1682  0.5077\n",
       " 0.0159  0.4891\n",
       " 0.4530 -0.2018\n",
       "-0.0812  0.6543\n",
       "-0.2457 -0.2078\n",
       " 0.5499  0.0322\n",
       " 0.4243  0.4551\n",
       "-0.1813  0.1856\n",
       " 0.0624 -0.3149\n",
       " 0.5154 -1.3526\n",
       " 0.0017 -0.1576\n",
       " 0.1401  0.1477\n",
       " 0.6947 -0.5255\n",
       " 0.3457  0.3892\n",
       " 1.0264  0.1815\n",
       " 0.4088  0.7533\n",
       " 1.0034 -0.1845\n",
       " 0.8940 -0.1769\n",
       " 0.7023  0.9734\n",
       "-0.5968  0.1197\n",
       " 0.5172 -0.0541\n",
       " 0.2553 -1.1658\n",
       " 0.3282  0.0340\n",
       " 0.5202  0.8162\n",
       "-0.0001 -0.1975\n",
       " 0.0452  0.3185\n",
       " 0.4530 -0.2018\n",
       " 0.7372  0.2343\n",
       "-0.1982  0.9024\n",
       " 0.5155  0.3044\n",
       " 0.0360 -0.0561\n",
       " 0.8649  0.4146\n",
       " 0.7869 -0.1296\n",
       "-0.0648 -0.2036\n",
       " 1.1041 -0.0161\n",
       " 0.3636 -0.7422\n",
       " 0.3466 -0.3059\n",
       " 0.3230 -0.1315\n",
       " 0.4356 -0.0263\n",
       "-0.2488 -0.3442\n",
       "-0.0637 -1.0482\n",
       "-0.0886 -0.8014\n",
       " 0.0552 -0.8336\n",
       "-0.1645  0.1785\n",
       " 0.7972  0.1205\n",
       " 0.5196 -0.4984\n",
       "-0.2076 -1.1928\n",
       " 1.0971 -0.1280\n",
       " 0.4637 -0.3910\n",
       "-0.0635 -0.7261\n",
       "-0.1348 -0.7662\n",
       " 0.7103  0.6634\n",
       "-0.0859  0.2292\n",
       " 0.6227  0.1886\n",
       " 0.3764 -0.7780\n",
       "-0.0114 -0.0672\n",
       "-0.0378  0.5392\n",
       " 0.8535 -0.2659\n",
       " 0.5944  1.0910\n",
       " 0.7883  0.0844\n",
       " 1.0347  0.5808\n",
       " 0.5196 -0.4984\n",
       "-0.1260  0.4301\n",
       " 0.9602 -0.6780\n",
       "-0.1095 -0.2554\n",
       " 0.6864  0.1562\n",
       " 0.7624 -0.7079\n",
       "-0.0385  0.0607\n",
       " 0.1222  0.2611\n",
       "-0.1070 -0.2652\n",
       " 0.5228  0.0397\n",
       " 0.6820  0.3814\n",
       " 0.1371  0.5774\n",
       " 2.7250 -0.8920\n",
       "-0.2859  0.0496\n",
       " 0.2746 -0.2194\n",
       " 1.1222  0.4003\n",
       " 0.4341  0.2669\n",
       " 0.0596 -1.0484\n",
       "-0.0173 -0.9050\n",
       " 0.3846 -0.0321\n",
       " 0.2767 -0.4597\n",
       " 1.7154  0.8930\n",
       " 0.4535 -1.4446\n",
       " 0.4969 -0.0703\n",
       " 1.4191  0.3964\n",
       " 0.8117  0.1921\n",
       " 0.3727  0.5488\n",
       " 0.5048 -0.6142\n",
       " 0.4894 -0.3719\n",
       " 0.2816  0.7473\n",
       "-0.1722  0.2538\n",
       " 0.0012  0.0334\n",
       " 0.6304  0.0659\n",
       " 0.9644  0.1230\n",
       " 0.3126  0.2182\n",
       " 0.5230  0.8701\n",
       " 0.4404 -0.0925\n",
       "-0.0306 -0.1153\n",
       " 0.8769  0.5496\n",
       " 0.1715 -0.9447\n",
       "-0.1430  0.7769\n",
       " 0.5946 -0.9488\n",
       "-0.3769 -0.1152\n",
       " 0.3958  0.5150\n",
       " 0.5021  0.5299\n",
       " 1.1704 -0.5313\n",
       " 0.6820  0.3814\n",
       " 0.4011  0.1977\n",
       " 0.0703 -0.1704\n",
       "-0.6371  0.2701\n",
       " 0.1785 -1.2692\n",
       " 0.3897 -0.5484\n",
       " 0.0794 -0.1910\n",
       " 0.6267  0.2094\n",
       " 0.5268  0.2046\n",
       " 1.3565 -0.3110\n",
       " 0.2873 -0.8455\n",
       " 1.7151  0.6141\n",
       " 0.2346  0.1361\n",
       " 1.4373 -0.0434\n",
       " 0.5184 -1.2231\n",
       " 0.8561 -0.7194\n",
       " 0.2947  0.2079\n",
       " 0.4470  0.0972\n",
       " 0.7742 -0.1030\n",
       " 0.4152  1.1341\n",
       " 0.3726  0.1213\n",
       " 0.3630  0.1620\n",
       " 0.3621  0.8120\n",
       " 0.4434 -0.1123\n",
       " 0.8575  1.3784\n",
       " 0.9965  0.0676\n",
       " 0.3243  0.7866\n",
       "-0.0635 -0.7261\n",
       " 0.3023  0.4942\n",
       " 0.9765  0.7981\n",
       " 1.1009  0.1452\n",
       "-0.3321 -0.0364\n",
       "-0.1769 -0.4398\n",
       " 0.5258 -0.3854\n",
       " 0.5871  0.1868\n",
       " 0.3516 -0.8675\n",
       " 1.3027 -0.3984\n",
       " 0.0309 -0.2921\n",
       " 0.4233 -0.9202\n",
       " 0.4556 -0.3495\n",
       "-0.3022  0.0601\n",
       " 0.0995 -0.3055\n",
       " 1.5742 -0.1129\n",
       " 0.7009  0.1819\n",
       " 0.1406  0.4468\n",
       " 1.0705  0.4302\n",
       "-0.4142  0.4483\n",
       " 0.3082  0.4417\n",
       "-0.1065 -0.1130\n",
       " 0.2376 -0.3897\n",
       " 0.7028  0.8283\n",
       "-1.1167 -1.5162\n",
       " 0.3457  0.3892\n",
       "-0.0762  0.4327\n",
       " 0.0318  1.9834\n",
       " 0.0836 -1.4013\n",
       " 1.3772  0.6038\n",
       " 1.0137 -0.9614\n",
       " 0.3698 -0.7717\n",
       "-0.0003 -1.2097\n",
       " 0.8776 -0.0149\n",
       " 0.2546  0.0367\n",
       " 0.8649  0.2214\n",
       " 0.7867  0.1669\n",
       " 0.6426  0.2681\n",
       " 0.5654 -0.9921\n",
       "-0.1676 -0.0313\n",
       " 0.4272  0.2674\n",
       "-0.0190 -0.3802\n",
       " 0.0142 -0.1758\n",
       "-0.0573 -0.0064\n",
       " 0.2327  0.7880\n",
       " 1.0762 -0.4359\n",
       " 0.7314  0.4920\n",
       " 0.4661  0.6788\n",
       " 0.1226  0.2590\n",
       " 0.3160  0.1019\n",
       "-0.2629 -0.2835\n",
       " 0.8880 -0.2053\n",
       " 0.5787 -0.1128\n",
       " 0.1393  0.6136\n",
       "-0.3111 -1.0378\n",
       " 0.2738 -0.3621\n",
       " 0.6923 -0.0272\n",
       " 0.4503  0.2650\n",
       "[torch.FloatTensor of size 320x2]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
